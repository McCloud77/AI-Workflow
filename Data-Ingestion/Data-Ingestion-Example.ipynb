{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study - Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "1. Given a business opportunity gather relevant data from multiple sources\n",
    "2. Clean the gathered data\n",
    "3. Create a script that gathers and cleans the data\n",
    "\n",
    "**The following files are needed to complete this case study**\n",
    "\n",
    "* this notebook\n",
    "* aavail-customers.db\n",
    "* aavail-steams.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you will be sourcing from is contained in two sources.\n",
    "\n",
    "1. A database ([SQLite](https://www.sqlite.org/index.html)) of `customer` data\n",
    "2. A [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values) of `stream` level data\n",
    "\n",
    "   >You will create a simple data pipeline that\n",
    "   (1) simplifies the data for future analysis and \n",
    "   (2) performs quality assurance checks.\n",
    "\n",
    "The process of building *the data ingestion pipeline* entails extracting data, transforming it, and loading into an appropriate data storage technology.  When constructing a pipeline it is important to keep in mind that they generally works in batches.  Data may be compiled during the day and the batch could be processed during the night.  The data pipeline may also be optimized to execute as a streaming computation that is, every event is handled as it occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1: Gathering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports needed for this case study\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the data exists in a database.  You can connect to is using the `sqlite3` package with the following function.  Note that is is good practice to wrap your connect functions in a `try-except` statement to cleanly handle exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(file_path):\n",
    "    try:\n",
    "        conn = sqlite3.connect(file_path)\n",
    "        print(\"...successfully connected to db\\n\")\n",
    "    except:\n",
    "        print(\"...unsuccessful connection\\n\")\n",
    "    return(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...successfully connected to db\n",
      "\n",
      "['CUSTOMERS', 'INVOICES', 'INVOICE_ITEMS']\n"
     ]
    }
   ],
   "source": [
    "# Make the connection to the database\n",
    "conn = connect_db('data/aavail-customers.db')\n",
    "# Print the table names\n",
    "tables = [t[0] for t in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")]\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_id\n",
      "customer_id\n",
      "last_name\n",
      "first_name\n",
      "gender\n",
      "age\n",
      "DOB\n",
      "city\n",
      "state\n",
      "country\n"
     ]
    }
   ],
   "source": [
    "# List columns in a table\n",
    "cursor = conn.execute('select * from sqlite_master')\n",
    "cursor.execute(\"PRAGMA table_info(CUSTOMERS)\")\n",
    "res = cursor.fetchall()\n",
    "for item in res:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Extract the relevant data from the DB.\n",
    "\n",
    "Query the database and extract the following data into a Pandas DataFrame. An online viewer for .DB files is available at https://inloop.github.io/sqlite-viewer/. The `CUSTOMERS` and `INVOICES` tables both have a 'customer_id' field while the `INVOICES` and `INVOICE_ITEMS` share the 'invoice_item_id' field.\n",
    "\n",
    "From the `CUSTOMERS` table extract:\n",
    "* Customer ID\n",
    "* Last name\n",
    "* First name\n",
    "* DOB\n",
    "* City\n",
    "* State\n",
    "* Country\n",
    "* Gender\n",
    "\n",
    "From the `INVOICES` table extract:\n",
    "* Invoice_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>invoice_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Kasen</td>\n",
       "      <td>07/30/98</td>\n",
       "      <td>Rock Hill</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>m</td>\n",
       "      <td>united_states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Garza</td>\n",
       "      <td>Ensley</td>\n",
       "      <td>04/12/89</td>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>f</td>\n",
       "      <td>singapore</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Carey</td>\n",
       "      <td>Lillian</td>\n",
       "      <td>09/12/97</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>f</td>\n",
       "      <td>united_states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Christensen</td>\n",
       "      <td>Beau</td>\n",
       "      <td>01/28/99</td>\n",
       "      <td>Hempstead</td>\n",
       "      <td>New York</td>\n",
       "      <td>m</td>\n",
       "      <td>united_states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>Ernesto</td>\n",
       "      <td>03/23/98</td>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>m</td>\n",
       "      <td>singapore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id    last_name first_name       DOB       city           state  \\\n",
       "0            1         Todd      Kasen  07/30/98  Rock Hill  South Carolina   \n",
       "1            2        Garza     Ensley  04/12/89  singapore            None   \n",
       "2            3        Carey    Lillian  09/12/97     Auburn         Alabama   \n",
       "3            4  Christensen       Beau  01/28/99  Hempstead        New York   \n",
       "4            5       Gibson    Ernesto  03/23/98  singapore            None   \n",
       "\n",
       "  gender        country  invoice_item_id  \n",
       "0      m  united_states                3  \n",
       "1      f      singapore                3  \n",
       "2      f  united_states                2  \n",
       "3      m  united_states                3  \n",
       "4      m      singapore                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract data from CUSTOMERS table\n",
    "query = \"\"\"\n",
    "SELECT cu.customer_id, cu.last_name, cu.first_name, cu.DOB,\n",
    "       cu.city, cu.state, cu.gender, cu.country, inv.invoice_item_id\n",
    "       FROM CUSTOMERS cu\n",
    "       INNER JOIN INVOICES inv\n",
    "       ON cu.customer_id = inv.customer_id;\n",
    "\"\"\"\n",
    "\n",
    "_data = [d for d in conn.execute(query)]\n",
    "columns = [\"customer_id\",\"last_name\",\"first_name\",\"DOB\",\"city\",\"state\",\"gender\",\"country\",\"invoice_item_id\"]\n",
    "df_db = pd.DataFrame(_data,columns=columns)\n",
    "df_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract the relevant data from the CSV file.\n",
    "\n",
    "For each ```customer_id``` determine if a customer has stopped their subscription or not and save it in a data container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19032, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>date</th>\n",
       "      <th>subscription_stopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1356</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1540</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1395</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1255</td>\n",
       "      <td>2018-12-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1697</td>\n",
       "      <td>2018-12-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  stream_id        date  subscription_stopped\n",
       "0            1       1356  2018-12-01                     0\n",
       "1            1       1540  2018-12-04                     0\n",
       "2            1       1395  2018-12-11                     0\n",
       "3            1       1255  2018-12-22                     0\n",
       "4            1       1697  2018-12-23                     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_streams = pd.read_csv(r\"data/aavail-streams.csv\")\n",
    "print(df_streams.shape)\n",
    "df_streams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_subscriber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  is_subscriber\n",
       "0            1              1\n",
       "1            2              0\n",
       "2            3              1\n",
       "3            4              1\n",
       "4            5              1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_ids = df_streams['customer_id'].values\n",
    "unique_ids = np.unique(df_streams['customer_id'].values)\n",
    "\n",
    "streams = df_streams['subscription_stopped'].values\n",
    "\n",
    "# For each unique ID (uid) determine subscription status\n",
    "has_churned = [0 if streams[customer_ids==uid].max() > 0 else 1 for uid in unique_ids]\n",
    "df_churn = pd.DataFrame({\"customer_id\": unique_ids, \"is_subscriber\": has_churned})\n",
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2: Cleaning the data\n",
    "\n",
    "Sometimes it is known in advance which types of data integrity issues to expect, but other times it is during the Exploratory Data Analysis (EDA) process that these issues are identified.  After extracting data it is important to include checks for quality assurance even on the first pass through the AI workflow.  Here, we will combine the data into a single structure and provide a couple checks for quality assurance.\n",
    "\n",
    "#### 3. Implement checks for quality assurance.\n",
    "\n",
    "1. Remove any repeat customers based on ```customer_id```\n",
    "2. Remove stream data that do not have an associated ```stream_id```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning Summary\n",
      "-----------------------------------\n",
      "Removed 7 duplicate rows\n",
      "Removed 0 missing stream ids\n",
      "\n",
      "Missing Value Summary\n",
      "-----------------------------------\n",
      "\n",
      "df_db\n",
      "---------------\n",
      "customer_id          0\n",
      "last_name            0\n",
      "first_name           0\n",
      "DOB                  0\n",
      "city                 0\n",
      "state              300\n",
      "gender               0\n",
      "country              0\n",
      "invoice_item_id      0\n",
      "dtype: int64\n",
      "\n",
      "df_streams\n",
      "---------------\n",
      "customer_id             0\n",
      "stream_id               0\n",
      "date                    0\n",
      "subscription_stopped    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCleaning Summary\\n{}\".format(\"-\"*35))\n",
    "\n",
    "duplicate_rows = df_db.duplicated()\n",
    "if True in duplicate_rows:\n",
    "    df_db = df_db[~duplicate_rows] \n",
    "print(\"Removed {} duplicate rows\".format(np.where(duplicate_rows==True)[0].size))\n",
    "\n",
    "missing_stream_ids = np.isnan(df_streams['stream_id'])\n",
    "if True in missing_stream_ids:\n",
    "    df_streams = df_streams[~missing_stream_ids]\n",
    "print(\"Removed {} missing stream ids\".format(np.where(missing_stream_ids==True)[0].size))\n",
    "\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(\"\\ndf_db\\n{}\".format(\"-\"*15))\n",
    "print(df_db.isnull().sum(axis = 0))\n",
    "print(\"\\ndf_streams\\n{}\".format(\"-\"*15))\n",
    "print(df_streams.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4: Combine the data into a single data structure\n",
    "\n",
    "For this example, the two most convenient structures for this task are Pandas dataframes and NumPy arrays.  At a minimum ensure that your structure accommodates the following.\n",
    "\n",
    "1. A column for `customer_id`\n",
    "2. A column for `country`\n",
    "3. A column for ```age``` that is created from ```DOB```\n",
    "4. A column ```customer_name``` that is created from ```first_name``` and ```last_name```\n",
    "5. A column to indicate churn called ```is_subscriber```\n",
    "7. A column that indicates ```subscriber_type``` that comes from ```invoice_items```\n",
    "6. A column to indicate the total ```num_streams```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique IDs\n",
    "df_clean = df_churn.copy()\n",
    "df_clean = df_clean[np.isin(df_clean['customer_id'].values, df_db['customer_id'].values)]\n",
    "unique_ids = df_clean['customer_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we are working with correctly ordered customer_ids df_db\n",
    "if not np.array_equal(df_clean['customer_id'], df_db['customer_id']): \n",
    "    raise Exception(\"Indexes are out of order or unmatched---needs to fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'aavail_basic', 2: 'aavail_premium', 3: 'aavail_unlimited'}\n"
     ]
    }
   ],
   "source": [
    "## Query the db to create an invoice item map\n",
    "query = \"\"\"\n",
    "SELECT i.invoice_item_id, i.invoice_item\n",
    "FROM INVOICE_ITEMS i;\n",
    "\"\"\"\n",
    "## Variables for new df creation\n",
    "invoice_item_map = {d[0]:d[1] for d in conn.execute(query)}\n",
    "print(invoice_item_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `db_df` contains 1000 rows with unique customer IDs and associated demographic data as well as the `invoice_item_id` associated with each customer ID. The dataframe `df_streams` contains the stream_ids, the date on which the stream occurred and whether the subscription was stopped for each customer_id. Note that there could be multiple rows for each customer. The dateframe `df_churn` contains customer IDs and a binary value (0/1) whether the subscription was stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>subscriber_type</th>\n",
       "      <th>num_streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>united_states</td>\n",
       "      <td>21</td>\n",
       "      <td>Kasen Todd</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>singapore</td>\n",
       "      <td>30</td>\n",
       "      <td>Ensley Garza</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>united_states</td>\n",
       "      <td>22</td>\n",
       "      <td>Lillian Carey</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>united_states</td>\n",
       "      <td>20</td>\n",
       "      <td>Beau Christensen</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>singapore</td>\n",
       "      <td>21</td>\n",
       "      <td>Ernesto Gibson</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  is_subscriber        country  age     customer_name  \\\n",
       "0            1              1  united_states   21        Kasen Todd   \n",
       "1            2              0      singapore   30      Ensley Garza   \n",
       "2            3              1  united_states   22     Lillian Carey   \n",
       "3            4              1  united_states   20  Beau Christensen   \n",
       "4            5              1      singapore   21    Ernesto Gibson   \n",
       "\n",
       "    subscriber_type  num_streams  \n",
       "0  aavail_unlimited           21  \n",
       "1  aavail_unlimited           16  \n",
       "2    aavail_premium           25  \n",
       "3  aavail_unlimited           18  \n",
       "4      aavail_basic           21  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new df\n",
    "df_clean['country'] = df_db['country']\n",
    "df_clean['age'] = np.datetime64('today') - df_db['DOB'].astype('datetime64')\n",
    "df_clean['customer_name'] = df_db['first_name'] + \" \" + df_db['last_name']\n",
    "df_clean['subscriber_type'] = df_db['invoice_item_id'].map(invoice_item_map)\n",
    "df_clean['num_streams'] = df_streams.groupby(['customer_id']).count()['stream_id'].values\n",
    "# Convert age to years\n",
    "df_clean['age'] = [a.astype('timedelta64[Y]').astype(int) for a in df_clean['age'].values]\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 3: Automating the process.\n",
    "\n",
    "To ensure that you code can be used to automate this process.  First save the dataframe (or numpy array) as a CSV file.  \n",
    "\n",
    "#### 5: Take the initial steps towards automation.\n",
    "\n",
    "1. Save cleaned, combined data as a CSV file.\n",
    "2. From the code above create a function or class that performs all of the steps given a database file and a streams CSV file.\n",
    "3. Run the function in batches and write a check to ensure you get the same result as compared to the code above.\n",
    "\n",
    "Shown below is some code that will split your streams file into two batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to split streams.csv into batches\n",
    "data_dir = \"data\"\n",
    "df_all = pd.read_csv(os.path.join(data_dir,\"aavail-streams.csv\"))\n",
    "\n",
    "half = int(round(df_all.shape[0] * 0.5))\n",
    "\n",
    "df_part1 = df_all[:half]\n",
    "df_part2 = df_all[half:]\n",
    "\n",
    "df_part1.to_csv(os.path.join(data_dir,\"aavail-streams-1.csv\"),index=False)\n",
    "df_part2.to_csv(os.path.join(data_dir,\"aavail-streams-2.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates how to save the function as a file from within a notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aavail-data-ingestor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aavail-data-ingestor.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "def connect_db(file_path):\n",
    "    \"\"\"\n",
    "    Function to connect to the aavail database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(file_path)\n",
    "        print(\"...successfully connected to db\")\n",
    "    except Error as e:\n",
    "        print(\"...unsuccessful connection\",e)\n",
    "    return(conn)\n",
    "\n",
    "def ingest_db_data(conn):\n",
    "    \"\"\"\n",
    "    Load and clean the db data\n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "            SELECT cu.customer_id, cu.last_name, cu.first_name, cu.DOB,\n",
    "            cu.city, cu.state, cu.gender, cu.country, inv.invoice_item_id\n",
    "            FROM CUSTOMERS cu\n",
    "            INNER JOIN INVOICES inv\n",
    "            ON cu.customer_id = inv.customer_id;\n",
    "            \"\"\"\n",
    "    _data = [d for d in conn.execute(query)]\n",
    "    columns = [\"customer_id\",\"last_name\",\"first_name\",\"DOB\",\"city\",\"state\",\"gender\",\"country\",\"invoice_item_id\"]\n",
    "    df_db = pd.DataFrame(_data,columns=columns)\n",
    "    \n",
    "    duplicate_rows = df_db.duplicated()\n",
    "    \n",
    "    if True in duplicate_rows:\n",
    "        df_db = df_db[~duplicate_rows]\n",
    "        df_db.reset_index()\n",
    "    print(\"... removed {} duplicate rows in db data\".format(np.where(duplicate_rows==True)[0].size))\n",
    "    return(df_db)\n",
    "\n",
    "def ingest_stream_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and clean the stream data\n",
    "    \"\"\"\n",
    "    \n",
    "    df_streams = pd.read_csv(file_path)\n",
    "    \n",
    "    customer_ids = df_streams['customer_id'].values\n",
    "    unique_ids = np.unique(df_streams['customer_id'].values)\n",
    "    streams = df_streams['subscription_stopped'].values\n",
    "    has_churned = [0 if streams[customer_ids==uid].max() > 0 else 1 for uid in unique_ids]\n",
    "    df_churn = pd.DataFrame({\"customer_id\": unique_ids, \"is_subscriber\": has_churned})\n",
    "    df_churn.head()\n",
    "    \n",
    "    missing_stream_ids = np.isnan(df_streams['stream_id'])    \n",
    "    if True in missing_stream_ids:\n",
    "        df_streams = df_streams[~missing_stream_ids]\n",
    "        df_streams.reset_index()\n",
    "    print(\"... removed {} missing stream ids\".format(np.where(missing_stream_ids==True)[0].size))\n",
    "    \n",
    "    return(df_streams, df_churn)\n",
    "\n",
    "def process_dataframes(df_db, df_streams, df_churn, conn):\n",
    "    \"\"\"\n",
    "    Add data to target csv\n",
    "    \"\"\"\n",
    "    df_clean = df_churn.copy()\n",
    "    df_db = df_db[np.isin(df_db['customer_id'].values,df_clean['customer_id'].values)]\n",
    "    df_db.reset_index()\n",
    "    unique_ids = df_clean['customer_id'].values\n",
    "\n",
    "    ## ensure we are working with correctly ordered customer_ids df_db\n",
    "    if not np.array_equal(df_clean['customer_id'],df_db['customer_id']):\n",
    "        raise Exception(\"indexes are out of order or unmatched---needs to fix\")\n",
    "\n",
    "    ## query the db t create a invoice item map\n",
    "    query = \"\"\"\n",
    "    SELECT i.invoice_item_id, i.invoice_item\n",
    "    FROM INVOICE_ITEMS i;\n",
    "    \"\"\"\n",
    "    invoice_item_map = {d[0]:d[1] for d in conn.execute(query)}\n",
    "    \n",
    "    ## variables for new df creation\n",
    "    df_clean['country'] = df_db['country']\n",
    "    df_clean['age'] = np.datetime64('today') - df_db['DOB'].astype('datetime64')\n",
    "    df_clean['customer_name'] = df_db['first_name'] + \" \" + df_db['last_name']\n",
    "    df_clean['subscriber_type'] = df_db['invoice_item_id'].map(invoice_item_map)\n",
    "    df_clean['num_streams'] = df_streams.groupby(['customer_id']).count()['stream_id'].values\n",
    "    # Convert age to years\n",
    "    df_clean['age'] = [a.astype('timedelta64[Y]').astype(int) for a in df_clean['age'].values]\n",
    "    \n",
    "    return(df_clean)\n",
    "\n",
    "def update_target(target_file, df_clean, overwrite=False):\n",
    "    \"\"\"\n",
    "    Update line by line in case data files are large\n",
    "    \"\"\"\n",
    "\n",
    "    if overwrite or not os.path.exists(target_file):\n",
    "        df_clean.to_csv(target_file, index=False)   \n",
    "    else:\n",
    "        df_target = pd.read_csv(target_file)\n",
    "        df_target.to_csv(target_file, mode='a', index=False)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    ## collect args\n",
    "    arg_string = \"%s -d db_filepath -s streams_filepath\"%sys.argv[0]\n",
    "    try:\n",
    "        optlist, args = getopt.getopt(sys.argv[1:],'d:s:')\n",
    "    except getopt.GetoptError:\n",
    "        print(getopt.GetoptError)\n",
    "        raise Exception(arg_string)\n",
    "\n",
    "    ## handle args\n",
    "    streams_file = None\n",
    "    db_file = None\n",
    "    for o, a in optlist:\n",
    "        if o == '-d':\n",
    "            db_file = a\n",
    "        if o == '-s':\n",
    "            streams_file = a\n",
    "    streams_file = os.path.join(DATA_DIR, streams_file)\n",
    "    db_file = os.path.join(DATA_DIR, db_file)\n",
    "    target_file = os.path.join(DATA_DIR, \"aavail-target.csv\")\n",
    "    \n",
    "    ## make the connection to the database\n",
    "    conn = connect_db(db_file)\n",
    "\n",
    "    ## ingest data base data\n",
    "    df_db = ingest_db_data(conn)\n",
    "    df_streams, df_churn = ingest_stream_data(streams_file)\n",
    "    df_clean = process_dataframes(df_db, df_streams, df_churn, conn)\n",
    "    \n",
    "    ## write\n",
    "    update_target(target_file, df_clean, overwrite=False)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the script just created using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-1.csv\n",
    "!python aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
